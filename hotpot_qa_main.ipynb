{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Checking python version\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUiqrgQATHsE",
        "outputId": "52964e2d-cd7b-498e-bd5f-cccff92464e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeuGvxgmS3Ht"
      },
      "outputs": [],
      "source": [
        "# Download and install Vieira\n",
        "# The default python version is for 3.10, you may change the link according to your python versions.\n",
        "%%capture\n",
        "!wget https://github.com/vieira-artifact/vieira-artifact-aaai24/releases/download/v0.2.2/vieira-0.2.2-cp310-cp310-manylinux_2_31_x86_64.whl\n",
        "!wget https://github.com/vieira-artifact/vieira-artifact-aaai24/releases/download/v0.2.2/vieira_ext-0.2.2-py3-none-any.whl\n",
        "!wget https://github.com/vieira-artifact/vieira-artifact-aaai24/releases/download/v0.2.2/vieira_gpu-0.0.1-py3-none-any.whl\n",
        "!wget https://github.com/vieira-artifact/vieira-artifact-aaai24/releases/download/v0.2.2/vieira_gpt-0.0.1-py3-none-any.whl\n",
        "!pip install vieira-0.2.2-cp310-cp310-manylinux_2_31_x86_64.whl\n",
        "!pip install vieira_ext-0.2.2-py3-none-any.whl\n",
        "!pip install vieira_gpu-0.0.1-py3-none-any.whl\n",
        "!pip install vieira_gpt-0.0.1-py3-none-any.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Vieira and related plugins\n",
        "import vieira\n",
        "import vieira_ext"
      ],
      "metadata": {
        "id": "XUCT02_IeoCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vieira with Embeddings and GPT"
      ],
      "metadata": {
        "id": "LT6yfd9afiLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vieira-artifact/vieira-artifact-aaai24/main/res/hotpot_examples.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anxThzo9WJHD",
        "outputId": "55a6a998-876c-4e06-fd96-60e1dcd21994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-06 01:57:52--  https://raw.githubusercontent.com/vieira-artifact/vieira-artifact-aaai24/main/res/hotpot_examples.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38394 (37K) [text/plain]\n",
            "Saving to: ‘hotpot_examples.json’\n",
            "\n",
            "\rhotpot_examples.jso   0%[                    ]       0  --.-KB/s               \rhotpot_examples.jso 100%[===================>]  37.49K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-11-06 01:57:53 (3.05 MB/s) - ‘hotpot_examples.json’ saved [38394/38394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "dataset = json.load(open('hotpot_examples.json', 'r'))"
      ],
      "metadata": {
        "id": "Cfq6IVsiWLgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your OpenAI API key if you want to run the example\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"YOUR-OPENAI-API-KEY-HERE\""
      ],
      "metadata": {
        "id": "CFPDL7jef701"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure Vieira plugins\n",
        "import argparse\n",
        "plugins = vieira_ext.PluginRegistry()\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "plugins.setup_argument_parser(parser)\n",
        "known_args, unknown_args = parser.parse_known_args()\n",
        "plugins.configure(known_args, unknown_args)"
      ],
      "metadata": {
        "id": "CSsFOp4kflnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROGRAM = \"\"\"\n",
        "@gpt_encoder\n",
        "type $embed_text(String) -> Tensor\n",
        "\n",
        "type question(q: String)\n",
        "\n",
        "type context(id: i32, c: String)\n",
        "\n",
        "rel relevant(id) = id := top<2>(id: question(q) and context(id, c) and soft_eq<Tensor>($embed_text(q), $embed_text(c)))\n",
        "rel relevant_context($string_concat(c1, \"\\n\", c2)) = relevant(id1) and relevant(id2) and id1 < id2 and context(id1, c1) and context(id2, c2)\n",
        "\n",
        "@gpt(\n",
        "  prompt=\"Given {{context}}\\n{{question}}\\nPlease think step-by-step {{answer}}\",\n",
        "  model=\"gpt-4\",\n",
        "  debug=false,\n",
        ")\n",
        "type qa(bound question: String, bound context: String, answer: String)\n",
        "\n",
        "rel answer(a) = question(q) and relevant_context(c) and qa(q, c, a)\n",
        "\n",
        "query answer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2kPWakhNWgzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hotpot QA\n",
        "for idx, example in enumerate(dataset):\n",
        "  ctx = vieira.Context()\n",
        "\n",
        "  plugins.load_into_ctx(ctx)\n",
        "  ctx.add_program(PROGRAM)\n",
        "  ctx.set_non_probabilistic(['question', 'context'])\n",
        "\n",
        "  question = example['question']\n",
        "  ctx.add_facts('question', [(question,)])\n",
        "  for i, document in enumerate(example['context']):\n",
        "    ctx.add_facts('context', [(i, document,)])\n",
        "\n",
        "  ctx.run()\n",
        "\n",
        "  result = list(ctx.relation('answer'))[0][0]\n",
        "  gt_answer = example['answer']\n",
        "  print(f\"{idx + 1}: {question}\\nmodel_answer: {result}\\ncorrect answer: {gt_answer}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNuQWRJ5hpkX",
        "outputId": "b7fa5d09-93a6-4c21-f61c-482bbd9fe823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Were Scott Derrickson and Ed Wood of the same nationality?\n",
            "model_answer: Yes, Scott Derrickson and Ed Wood are of the same nationality\n",
            "correct answer: yes\n",
            "\n",
            "\n",
            "2: The arena where the Lewiston Maineiacs played their home games can seat how many people?\n",
            "model_answer: The information provided does not include the seating capacity of the arena where the Lewiston Maineiacs played their home games.\n",
            "correct answer: 3,677 seated\n",
            "\n",
            "\n",
            "3: Are Local H and For Against both from the United States?\n",
            "model_answer: \n",
            "correct answer: yes\n",
            "\n",
            "\n",
            "4: When did the English local newspaper, featuring the sculpture and war memorial in the Forbury gardens, change names?\n",
            "model_answer: The information provided does not contain details about when the English local newspaper, featuring the sculpture and war memorial in the Forbury gardens, changed names.\n",
            "correct answer: 2009\n",
            "\n",
            "\n",
            "5: What airport serviced by American Airlines Shuttle, is also the largest airport in the New England region and 17th busiest in the U.S?\n",
            "model_answer: Logan International Airport\n",
            "correct answer: Logan International Airport\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
